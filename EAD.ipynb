{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "events_csv = 'data/train_events.csv'\n",
    "data_csv = \"data/train_series.parquet\"\n",
    "\n",
    "def read_data(verbose=True, rd=True, re=True):\n",
    "    events, data = None, None\n",
    "    if re:\n",
    "        if verbose: \n",
    "            print(f\"Reading {events_csv}\")\n",
    "            t=time.time()\n",
    "        events = pd.read_csv(events_csv)\n",
    "        if verbose: \n",
    "            print(f\"Read {len(events)} rows from {events_csv} in {time.time()-t:.3f} seconds\")\n",
    "    if rd:\n",
    "        if verbose:\n",
    "            print(f\"Reading {data_csv}\")\n",
    "            t=time.time()\n",
    "        data = pd.read_parquet(data_csv, engine='fastparquet')\n",
    "        if verbose: \n",
    "            print(f\"Read {len(data)} rows from {data_csv} in {time.time()-t:.3f} seconds\")\n",
    "    return data, events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/train_events.csv\n",
      "Read 14508 rows from data/train_events.csv in 0.056 seconds\n",
      "Reading data/train_series.parquet\n",
      "Read 127946340 rows from data/train_series.parquet in 73.314 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(221, 56)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,events = read_data()\n",
    "train_sids, test_sids = train_test_split(events['series_id'].unique(), train_size=0.8, random_state=42)\n",
    "train_sids.shape, test_sids.shape\n",
    "train_sids, test_sids = [set(i) for i in [train_sids, test_sids]]\n",
    "len(train_sids), len(test_sids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127946340, '5aad18e7ce64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), next(iter(train_sids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42542460</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-05T17:00:00-0500</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42542461</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-02-05T17:00:05-0500</td>\n",
       "      <td>-27.239401</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42542462</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-02-05T17:00:10-0500</td>\n",
       "      <td>-47.353199</td>\n",
       "      <td>0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42542463</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-02-05T17:00:15-0500</td>\n",
       "      <td>-26.554701</td>\n",
       "      <td>0.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42542464</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-02-05T17:00:20-0500</td>\n",
       "      <td>-16.809799</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952855</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>410395.0</td>\n",
       "      <td>2018-03-01T10:59:35-0500</td>\n",
       "      <td>-46.804100</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952856</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>410396.0</td>\n",
       "      <td>2018-03-01T10:59:40-0500</td>\n",
       "      <td>-40.997799</td>\n",
       "      <td>0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952857</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>410397.0</td>\n",
       "      <td>2018-03-01T10:59:45-0500</td>\n",
       "      <td>-41.273701</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952858</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>410398.0</td>\n",
       "      <td>2018-03-01T10:59:50-0500</td>\n",
       "      <td>-41.259899</td>\n",
       "      <td>0.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952859</th>\n",
       "      <td>5aad18e7ce64</td>\n",
       "      <td>410399.0</td>\n",
       "      <td>2018-03-01T10:59:55-0500</td>\n",
       "      <td>-40.717899</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             series_id      step                 timestamp     anglez    enmo\n",
       "42542460  5aad18e7ce64       0.0  2018-02-05T17:00:00-0500   0.837300  0.0850\n",
       "42542461  5aad18e7ce64       1.0  2018-02-05T17:00:05-0500 -27.239401  0.0558\n",
       "42542462  5aad18e7ce64       2.0  2018-02-05T17:00:10-0500 -47.353199  0.0484\n",
       "42542463  5aad18e7ce64       3.0  2018-02-05T17:00:15-0500 -26.554701  0.1502\n",
       "42542464  5aad18e7ce64       4.0  2018-02-05T17:00:20-0500 -16.809799  0.1135\n",
       "...                ...       ...                       ...        ...     ...\n",
       "42952855  5aad18e7ce64  410395.0  2018-03-01T10:59:35-0500 -46.804100  0.0150\n",
       "42952856  5aad18e7ce64  410396.0  2018-03-01T10:59:40-0500 -40.997799  0.0143\n",
       "42952857  5aad18e7ce64  410397.0  2018-03-01T10:59:45-0500 -41.273701  0.0125\n",
       "42952858  5aad18e7ce64  410398.0  2018-03-01T10:59:50-0500 -41.259899  0.0166\n",
       "42952859  5aad18e7ce64  410399.0  2018-03-01T10:59:55-0500 -40.717899  0.0256\n",
       "\n",
       "[410400 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['series_id']=='5aad18e7ce64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series_id       0\n",
       "night           0\n",
       "event           0\n",
       "step         4923\n",
       "timestamp    4923\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacheck = events.isna()\n",
    "nacheck['series_id'] = events['series_id']\n",
    "nacheck = nacheck.groupby('series_id').sum()\n",
    "nonas = nacheck.loc[nacheck['step']==0]\n",
    "nonas.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['series_id'].unique().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4923, 14508, 9585)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacheck.sum()['step'] , events.__len__() , events.dropna().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.head(1279463)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 ms Â± 59.4 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "idx = [i in train_sids for i in df['series_id']]\n",
    "train_events = df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 ms Â± 4.34 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "idx = df['series_id'].apply(lambda i: i in train_sids)\n",
    "train_events = df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'parr' from 'd:\\\\Projects\\\\ChildMindSleep\\\\parr.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import parr\n",
    "from itertools import repeat\n",
    "importlib.reload(parr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.72 s Â± 643 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "idx = parr.parallelize(parr.series_id_in_series_set, df['series_id'], repeat(train_sids, len(df['series_id'])))\n",
    "train_events = df[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('abc') is str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import parr\n",
    "from itertools import repeat\n",
    "\n",
    "def load_training_data(train_val_split=0.8, verbose=True, seed=42):\n",
    "    events_csv = 'data/train_events.csv'\n",
    "    if verbose: \n",
    "        print(f\"Reading {events_csv}\")\n",
    "        t=time.time()\n",
    "    events = pd.read_csv(events_csv)\n",
    "    if verbose: \n",
    "        print(f\"Read {len(events)} rows from {events_csv} in {time.time()-t} seconds\")\n",
    "    series_ids = events['series_id'].unique()\n",
    "    train_ids, val_ids = train_test_split(series_ids, train_size=train_val_split, random_state=seed)\n",
    "    train_ids, val_ids = set(train_ids), set(val_ids)\n",
    "    train_events = events.loc[events['series_id'].apply(lambda i: i in train_ids)]\n",
    "    val_events = events.loc[events['series_id'].apply(lambda i: i in val_ids)]\n",
    "\n",
    "\n",
    "    data_csv = \"data/train_series.parquet\"\n",
    "    if verbose: \n",
    "        print(f\"Reading {data_csv}\")\n",
    "        t=time.time()\n",
    "    data = pd.read_parquet(data_csv, engine='fastparquet')\n",
    "    if verbose: \n",
    "        print(f\"Read {len(data)} rows from {data_csv} in {time.time()-t} seconds\")\n",
    "        print(\"Getting indexs of training data from the data csv\")\n",
    "        t=time.time()\n",
    "    train_idx = parr.parallelize(parr.series_id_in_series_set, data['series_id'], repeat(train_ids), total=len(data))\n",
    "    if verbose: \n",
    "        print(f\"Got indexes of training data from data csv in {time.time()-t} seconds\")\n",
    "        print(f\"Spitting the training data from the data csv\")\n",
    "        t=time.time()\n",
    "    train_data = data.loc[train_idx]\n",
    "    if verbose:\n",
    "        print(f\"Splitted training data in {time.time()-t} seconds\")\n",
    "    if verbose: \n",
    "        print(f\"Spitting the validation data from the data csv\")\n",
    "        t=time.time()\n",
    "    val_data = data.loc[[i in val_ids for i in data['series_id']]]\n",
    "    if verbose:\n",
    "        print(f\"Splitted validation data in {time.time()-t} seconds\")\n",
    "    if verbose: print(f\"Done splitting the data\")\n",
    "\n",
    "\n",
    "    return train_data, train_events, val_data, val_events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/train_events.csv\n",
      "Read 14508 rows from data/train_events.csv in 0.035845041275024414 seconds\n",
      "Reading data/train_series.parquet\n",
      "Read 127946340 rows from data/train_series.parquet in 69.02580213546753 seconds\n",
      "Getting indexs of training data from the data csv\n",
      "with tqdm\n"
     ]
    }
   ],
   "source": [
    "td, te, vd, ve = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import parr\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "s = pd.Series('a b c d e f g h i j k l m n o p'.split())\n",
    "series_set = set('d e f g h'.split())\n",
    "parr.parallelize(parr.series_id_in_series_set, s, itertools.repeat(series_set))\n",
    "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#     res = list(executor.map(parr.series_id_in_series_set, s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td, te, vd, ve = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['series_id']=='038441c925bb'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading up the Data\n",
    "\n",
    "The data will be loaded from the following two files\n",
    "\n",
    "- data/train_events.csv\n",
    "- data/train_series.parquet\n",
    "\n",
    "into two pandas dataframe `events` and `series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('data/train_events.csv')\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_parquet(\"data/train_series.parquet\", engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(series), len(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Evaluation metric\n",
    "\n",
    "Here I'm checking to see the evaluation metric works as I would expect it to work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load up sample submissions\n",
    "sample = pd.read_csv(\"data/sample_submission.csv\", index_col='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ids = sample['series_id'].unique()\n",
    "s_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = events[['series_id', 'event', 'step']]\n",
    "ground_truths.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = ground_truths.dropna()\n",
    "ground_truths.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In evaluations module\n",
    "\n",
    "```py\n",
    "def scoreIt(preds_df: pd.DataFrame, targs_df: pd.DataFrame):\n",
    "    tol = [12, 36, 60, 90, 120, 150, 180, 240, 300, 360]\n",
    "    tol = [float(i) for i in tol]\n",
    "    tols = {\n",
    "        'onset': tol,\n",
    "        'wakeup': tol\n",
    "    }\n",
    "    return evaluations.score(\n",
    "        solution=targs_df,\n",
    "        submission=preds_df,\n",
    "        tolerances=tols,\n",
    "        series_id_column_name='series_id',\n",
    "        time_column_name='step',\n",
    "        event_column_name='event',\n",
    "        score_column_name='score',\n",
    "    )\n",
    "```\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations.scoreIt(sample, ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = ground_truths.iloc[:10]\n",
    "s2.loc[:,'score']=[(i%10)/10 for i in range(len(s2))]\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations.scoreIt(s2, ground_truths.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "s3 = s2.copy()\n",
    "r = 10\n",
    "s3.loc[:,'step'] += [random.randint(-1*r,r) for _ in range(len(s3))]\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations.scoreIt(s3, ground_truths.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "sqrt((s3['step'] - s2['step']).apply(lambda i: i**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = s3\n",
    "s4.loc[:,'step'] = 10\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations.scoreIt(s4, ground_truths.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
